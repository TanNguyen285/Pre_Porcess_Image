import cv2
import numpy as np
import onnxruntime as ort
import os

# --- C·∫§U H√åNH ---
# √îng nh·ªõ ƒë·ªïi ƒë∆∞·ªùng d·∫´n tr·ªè ƒë√∫ng v√†o file .onnx nh√©
ONNX_PATH  = r"Convert-Zero-DCE++\zerodce.onnx" 
IMAGE_PATH = "test_image.jpg"

print("\n--- ZERO-DCE++ ONNX RUNTIME TEST ---")

# 1. Ki·ªÉm tra file
if not os.path.exists(ONNX_PATH):
    print(f"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file model t·∫°i: {ONNX_PATH}")
    print("üëâ H√£y ch·∫Øc ch·∫Øn √¥ng ƒë√£ c√≥ file .onnx (n·∫øu ch∆∞a c√≥ th√¨ export t·ª´ .pth sang)")
    exit()

# 2. Load Model ONNX
# T·ª± ƒë·ªông ch·ªçn GPU (CUDA) n·∫øu c√≥, kh√¥ng th√¨ ch·∫°y CPU
providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
try:
    session = ort.InferenceSession(ONNX_PATH, providers=providers)
except Exception as e:
    print(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o (c√≥ th·ªÉ do ch∆∞a c√†i CUDA), chuy·ªÉn sang CPU...")
    session = ort.InferenceSession(ONNX_PATH, providers=['CPUExecutionProvider'])

# L·∫•y t√™n Input/Output t·ª± ƒë·ªông (Kh·ªèi lo sai t√™n layer)
input_name = session.get_inputs()[0].name
output_name = session.get_outputs()[0].name
print(f"‚úÖ Model Loaded! Input: '{input_name}' -> Output: '{output_name}'")

# 3. ƒê·ªçc ·∫£nh
img = cv2.imread(IMAGE_PATH)
if img is None:
    print("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y ·∫£nh input!")
    exit()

h_orig, w_orig = img.shape[:2]

# 4. Chu·∫©n b·ªã Input (Pre-processing)
# Resize v·ªÅ 320x320 (K√≠ch th∆∞·ªõc chu·∫©n c·ªßa Zero-DCE)
target_w, target_h = 320, 320
img_resized = cv2.resize(img, (target_w, target_h))

# ƒê·ªïi BGR -> RGB
img_in = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)

# Normalize: Chia 255 ƒë·ªÉ v·ªÅ kho·∫£ng [0, 1]
img_in = img_in.astype(np.float32) / 255.0

# Transpose: ƒê·ªïi tr·ª•c t·ª´ (H, W, C) -> (C, H, W) 
# (ƒê√¢y l√† b∆∞·ªõc NCNN t·ª± l√†m, nh∆∞ng ONNX ph·∫£i l√†m th·ªß c√¥ng)
img_in = img_in.transpose(2, 0, 1)

# Th√™m dimension Batch: (3, 320, 320) -> (1, 3, 320, 320)
img_in = np.expand_dims(img_in, axis=0)

# 5. Ch·∫°y Model (Inference)
# Tr·∫£ v·ªÅ list k·∫øt qu·∫£, l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n [0]
outputs = session.run([output_name], {input_name: img_in})
output_tensor = outputs[0]

# 6. X·ª≠ l√Ω Output (Post-processing)
# B·ªè dimension Batch: (1, 3, 320, 320) -> (3, 320, 320)
result = np.squeeze(output_tensor)

# ƒê·ªïi tr·ª•c ng∆∞·ª£c l·∫°i: (C, H, W) -> (H, W, C) ƒë·ªÉ hi·ªÉn th·ªã
result = result.transpose(1, 2, 0)

# Nh√¢n 255 v√† clip gi√° tr·ªã ƒë·ªÉ kh√¥ng b·ªã l·ªói m√†u
result = (result * 255.0).clip(0, 255).astype(np.uint8)

# ƒê·ªïi RGB -> BGR
result_bgr = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)

# Resize v·ªÅ k√≠ch th∆∞·ªõc g·ªëc
result_final = cv2.resize(result_bgr, (w_orig, h_orig))

# 7. Hi·ªÉn th·ªã
cv2.putText(img, "ORIGINAL", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
cv2.putText(result_final, "ONNX ENHANCED", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

combined = np.hstack((img, result_final))
cv2.imshow("Zero-DCE ONNX Result", combined)

print("üëâ ƒê√£ hi·ªán ·∫£nh. B·∫•m ph√≠m b·∫•t k·ª≥ ƒë·ªÉ tho√°t.")
cv2.waitKey(0)
cv2.destroyAllWindows()