import torch
import torch.nn as nn
import torch.nn.functional as F
import os

# --- Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ---
# Ã”ng kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n nÃ y cho Ä‘Ãºng vá»‹ trÃ­ file Epoch99.pth trÃªn mÃ¡y Ã´ng
MODEL_PATH = r'Zero-DCE_extension-main/Zero-DCE++/snapshots_Zero_DCE++/Epoch99.pth'
ONNX_OUTPUT = "zerodce.onnx"

print(f"\n--- FIX EXPORT ONNX ZERO-DCE++ ---")

# 1. Äá»ŠNH NGHÄ¨A KIáº¾N TRÃšC MODEL (ChÃ©p tháº³ng vÃ o Ä‘Ã¢y cho an toÃ n)
class enhance_net_nopool(nn.Module):
    def __init__(self, scale_factor=1):
        super(enhance_net_nopool, self).__init__()
        self.relu = nn.ReLU(inplace=True)
        number_f = 32

        # Zero-DCE++ dÃ¹ng Depthwise Separable Conv Ä‘á»ƒ nháº¹ hÆ¡n
        self.e_conv1 = nn.Conv2d(3, number_f, 3, 1, 1, bias=True)
        self.e_conv2 = nn.Conv2d(number_f, number_f, 3, 1, 1, bias=True)
        self.e_conv3 = nn.Conv2d(number_f, number_f, 3, 1, 1, bias=True)
        self.e_conv4 = nn.Conv2d(number_f, number_f, 3, 1, 1, bias=True)
        self.e_conv5 = nn.Conv2d(number_f * 2, number_f, 3, 1, 1, bias=True)
        self.e_conv6 = nn.Conv2d(number_f * 2, number_f, 3, 1, 1, bias=True)
        self.e_conv7 = nn.Conv2d(number_f * 2, 24, 3, 1, 1, bias=True)

    def enhance(self, x, x_r):
        x = x + x_r * (torch.pow(x, 2) - x)
        x = x + x_r * (torch.pow(x, 2) - x)
        x = x + x_r * (torch.pow(x, 2) - x)
        enhance_image_1 = x + x_r * (torch.pow(x, 2) - x)
        x = enhance_image_1 + x_r * (torch.pow(enhance_image_1, 2) - enhance_image_1)
        x = x + x_r * (torch.pow(x, 2) - x)
        x = x + x_r * (torch.pow(x, 2) - x)
        enhance_image = x + x_r * (torch.pow(x, 2) - x)
        return enhance_image

    def forward(self, x):
        x1 = self.relu(self.e_conv1(x))
        x2 = self.relu(self.e_conv2(x1))
        x3 = self.relu(self.e_conv3(x2))
        x4 = self.relu(self.e_conv4(x3))

        x5 = self.relu(self.e_conv5(torch.cat([x3, x4], 1)))
        x6 = self.relu(self.e_conv6(torch.cat([x2, x5], 1)))
        
        # Output params map
        x_r = F.tanh(self.e_conv7(torch.cat([x1, x6], 1)))
        
        # Split params
        r1, r2, r3, r4, r5, r6, r7, r8 = torch.split(x_r, 3, dim=1)
        
        # Iterative enhancement
        x = x + r1 * (torch.pow(x, 2) - x)
        x = x + r2 * (torch.pow(x, 2) - x)
        x = x + r3 * (torch.pow(x, 2) - x)
        enhance_image_1 = x + r4 * (torch.pow(x, 2) - x)
        x = enhance_image_1 + r5 * (torch.pow(enhance_image_1, 2) - enhance_image_1)
        x = x + r6 * (torch.pow(x, 2) - x)
        x = x + r7 * (torch.pow(x, 2) - x)
        enhance_image = x + r8 * (torch.pow(x, 2) - x)
        
        return enhance_image, x_r

# 2. KHá»I Táº O VÃ€ LOAD TRá»ŒNG Sá»
print(">>> Äang khá»Ÿi táº¡o model...")
net = enhance_net_nopool(scale_factor=1).cpu()

if not os.path.exists(MODEL_PATH):
    print(f"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file {MODEL_PATH}")
    print("ğŸ‘‰ Ã”ng sá»­a láº¡i dÃ²ng MODEL_PATH á»Ÿ Ä‘áº§u file code nhÃ©.")
    exit()

try:
    # Fix 1: map_location='cpu' thay vÃ¬ '0'
    checkpoint = torch.load(MODEL_PATH, map_location='cpu')
    
    # Fix 2: Xá»­ lÃ½ key 'module.' náº¿u cÃ³ (do DataParallel)
    new_state_dict = {}
    for k, v in checkpoint.items():
        name = k.replace('module.', '') 
        new_state_dict[name] = v
        
    # Load vá»›i strict=True Ä‘á»ƒ Ä‘áº£m báº£o file pth Ä‘Ãºng chuáº©n
    net.load_state_dict(new_state_dict, strict=True)
    net.eval()
    print("âœ… Load weights thÃ nh cÃ´ng!")
    
except Exception as e:
    print(f"âŒ Lá»—i load file .pth: {e}")
    # Náº¿u váº«n lá»—i, thá»­ load lá»ng láº»o hÆ¡n
    print("âš ï¸ Äang thá»­ load láº¡i vá»›i strict=False...")
    try:
        net.load_state_dict(checkpoint, strict=False)
        print("âœ… Load (strict=False) thÃ nh cÃ´ng!")
    except:
        exit()

# 3. WRAPPER Äá»‚ CHá»ˆ Láº¤Y áº¢NH OUTPUT
class ModelWrapper(nn.Module):
    def __init__(self, model):
        super(ModelWrapper, self).__init__()
        self.model = model
    
    def forward(self, x):
        # enhance_net_nopool tráº£ vá» (image, params)
        # Ta chá»‰ láº¥y cÃ¡i Ä‘áº§u tiÃªn [0]
        result = self.model(x)
        if isinstance(result, tuple):
            return result[0]
        return result

wrapped_net = ModelWrapper(net)
wrapped_net.eval()

# 4. EXPORT ONNX
dummy_input = torch.randn(1, 3, 320, 320)

print(f">>> Äang convert sang {ONNX_OUTPUT}...")

torch.onnx.export(
    wrapped_net,
    dummy_input,
    ONNX_OUTPUT,
    export_params=True,
    opset_version=11,      # Báº£n chuáº©n nháº¥t cho ONNX Runtime
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output']
)

print(f"ğŸ‰ THÃ€NH CÃ”NG! File '{ONNX_OUTPUT}' Ä‘Ã£ sáºµn sÃ ng.")
print("ğŸ‘‰ Giá» Ã´ng cháº¡y file test báº±ng ONNX Runtime lÃ  Ä‘Æ°á»£c.")